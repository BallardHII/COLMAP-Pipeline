{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547ce6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First cell - Import necessary libraries\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import json\n",
    "import numpy as np\n",
    "import warnings\n",
    "import urllib3\n",
    "\n",
    "# Suppress SSL warnings\n",
    "warnings.filterwarnings('ignore', category=urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Base directory setup\n",
    "base_dir = \"C:/Users/zzballabe1/visualdigitaltwin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Download data from S3 bucket\n",
    "import boto3\n",
    "import os\n",
    "import warnings\n",
    "import urllib3\n",
    "import zipfile\n",
    "\n",
    "# Suppress SSL warnings\n",
    "warnings.filterwarnings('ignore', category=urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def download_from_s3(bucket_name, prefix, local_dir, file_limit=None):\n",
    "    \"\"\"\n",
    "    Download files from S3 bucket to local directory\n",
    "    Args:\n",
    "        bucket_name: S3 bucket name\n",
    "        prefix: Path prefix in the bucket\n",
    "        local_dir: Local directory to save files\n",
    "        file_limit: Maximum number of files to download (None for all)\n",
    "    \"\"\"\n",
    "    # Configure S3 client\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        region_name='us-gov-west-1',\n",
    "        verify=False\n",
    "    )\n",
    "    \n",
    "    # Create local directory if it doesn't exist\n",
    "    os.makedirs(local_dir, exist_ok=True)\n",
    "    \n",
    "    # List objects in the bucket with the given prefix\n",
    "    print(f\"Listing objects in s3://{bucket_name}/{prefix}\")\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix=prefix\n",
    "    )\n",
    "    \n",
    "    if 'Contents' not in response:\n",
    "        print(f\"No objects found in s3://{bucket_name}/{prefix}\")\n",
    "        return []\n",
    "    \n",
    "    # Get the list of objects\n",
    "    objects = response['Contents']\n",
    "    if file_limit:\n",
    "        objects = objects[:file_limit]\n",
    "    \n",
    "    # Download each object\n",
    "    downloaded_files = []\n",
    "    for obj in objects:\n",
    "        key = obj['Key']\n",
    "        filename = os.path.basename(key)\n",
    "        local_path = os.path.join(local_dir, filename)\n",
    "        \n",
    "        # Skip if file already exists\n",
    "        if os.path.exists(local_path) and os.path.getsize(local_path) == obj['Size']:\n",
    "            print(f\"Skipping {filename} (already exists)\")\n",
    "            downloaded_files.append(local_path)\n",
    "            continue\n",
    "        \n",
    "        # Download the file\n",
    "        print(f\"Downloading {key} ({obj['Size']/1024/1024:.2f} MB)\")\n",
    "        s3_client.download_file(\n",
    "            bucket_name,\n",
    "            key,\n",
    "            local_path\n",
    "        )\n",
    "        downloaded_files.append(local_path)\n",
    "    \n",
    "    print(f\"Downloaded {len(downloaded_files)} files to {local_dir}\")\n",
    "    return downloaded_files\n",
    "\n",
    "def extract_zip_file(zip_path, extract_to):\n",
    "    \"\"\"Extract contents of a zip file\"\"\"\n",
    "    print(f\"Extracting {zip_path} to {extract_to}\")\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    \n",
    "    print(f\"Extracted zip contents to {extract_to}\")\n",
    "    return extract_to\n",
    "\n",
    "def download_video_from_s3():\n",
    "    \"\"\"Download video file from S3 bucket\"\"\"\n",
    "    bucket_name = 'hiitsd-mt-visualdigitaltwin-conf-room'\n",
    "    prefix = 'Conference-Room-14OCT2025-Camera/'\n",
    "    video_dir = os.path.join(base_dir, \"video\")\n",
    "    \n",
    "    try:\n",
    "        # List all files in the prefix\n",
    "        s3_client = boto3.client(\n",
    "            's3',\n",
    "            region_name='us-gov-west-1',\n",
    "            verify=False\n",
    "        )\n",
    "        \n",
    "        response = s3_client.list_objects_v2(\n",
    "            Bucket=bucket_name,\n",
    "            Prefix=prefix\n",
    "        )\n",
    "        \n",
    "        if 'Contents' not in response:\n",
    "            print(f\"No objects found in s3://{bucket_name}/{prefix}\")\n",
    "            return None\n",
    "        \n",
    "        # First try to download the MOV file\n",
    "        mov_key = prefix + 'conf_room_14OCT-CAM.MOV'\n",
    "        mov_path = os.path.join(video_dir, 'conf_room_14OCT-CAM.MOV')\n",
    "        \n",
    "        try:\n",
    "            print(f\"Attempting to download video file: {mov_key}\")\n",
    "            os.makedirs(video_dir, exist_ok=True)\n",
    "            s3_client.download_file(bucket_name, mov_key, mov_path)\n",
    "            print(f\"Successfully downloaded video to {mov_path}\")\n",
    "            return mov_path\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading MOV file: {e}\")\n",
    "            \n",
    "        # If MOV fails, try the ZIP file\n",
    "        zip_key = prefix + 'confroom_14OCT2025-CAM.zip'\n",
    "        zip_path = os.path.join(video_dir, 'confroom_14OCT2025-CAM.zip')\n",
    "        \n",
    "        try:\n",
    "            print(f\"Attempting to download ZIP file: {zip_key}\")\n",
    "            os.makedirs(video_dir, exist_ok=True)\n",
    "            s3_client.download_file(bucket_name, zip_key, zip_path)\n",
    "            print(f\"Successfully downloaded ZIP to {zip_path}\")\n",
    "            \n",
    "            # Extract the ZIP file\n",
    "            extract_dir = os.path.join(base_dir, \"extracted\")\n",
    "            extract_zip_file(zip_path, extract_dir)\n",
    "            \n",
    "            # Look for video files in the extracted directory\n",
    "            for root, _, files in os.walk(extract_dir):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('.mov', '.mp4')):\n",
    "                        video_path = os.path.join(root, file)\n",
    "                        print(f\"Found video in ZIP: {video_path}\")\n",
    "                        return video_path\n",
    "            \n",
    "            print(\"No video files found in the ZIP archive\")\n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading ZIP file: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing S3: {e}\")\n",
    "    \n",
    "    # If all else fails, try to download images directly\n",
    "    print(\"Downloading images from previous dataset...\")\n",
    "    images_dir = os.path.join(base_dir, \"images\")\n",
    "    download_from_s3(\n",
    "        bucket_name,\n",
    "        'post_model_dataset_jpgs/jpgs/jpgs/',\n",
    "        images_dir,\n",
    "        file_limit=100  # Limit to 100 images for testing\n",
    "    )\n",
    "    \n",
    "    # Also download camera data if needed\n",
    "    cameras_dir = os.path.join(base_dir, \"cameras\")\n",
    "    download_from_s3(\n",
    "        bucket_name,\n",
    "        'post_model_dataset/cameras/cameras/',\n",
    "        cameras_dir,\n",
    "        file_limit=100\n",
    "    )\n",
    "    \n",
    "    return None  # No video downloaded, but images are available\n",
    "\n",
    "def run_complete_workflow_with_s3(target_label=\"dog\",\n",
    "                                 bucket_name='hiitsd-mt-visualdigitaltwin-conf-room',\n",
    "                                 video_prefix='Conference-Room-14OCT2025-Camera/',\n",
    "                                 video_filename='conf_room_14OCT-CAM.MOV',\n",
    "                                 zip_filename='confroom_14OCT2025-CAM.zip',\n",
    "                                 fallback_images_prefix='post_model_dataset_jpgs/jpgs/jpgs/',\n",
    "                                 fallback_cameras_prefix='post_model_dataset/cameras/cameras/',\n",
    "                                 clear_previous_data=True):\n",
    "    \"\"\"\n",
    "    Run the complete workflow using data from S3\n",
    "    Args:\n",
    "        target_label: Object label to detect and project to 3D\n",
    "        bucket_name: S3 bucket name\n",
    "        video_prefix: Path prefix for the video files\n",
    "        video_filename: Name of the video file to download\n",
    "        zip_filename: Name of the zip file to download as fallback\n",
    "        fallback_images_prefix: Path prefix for fallback images\n",
    "        fallback_cameras_prefix: Path prefix for fallback camera data\n",
    "        clear_previous_data: Whether to clear previous data before starting\n",
    "    \"\"\"\n",
    "    print(\"=== Visual Digital Twin Workflow with S3 ===\")\n",
    "    \n",
    "    # Set up directories\n",
    "    images_dir = os.path.join(base_dir, \"images\")\n",
    "    frames_dir = os.path.join(base_dir, \"frames\")\n",
    "    colmap_dir = os.path.join(base_dir, \"colmap\")\n",
    "    \n",
    "    # Clear previous data if requested\n",
    "    if clear_previous_data:\n",
    "        print(\"\\n=== Clearing previous data ===\")\n",
    "        for dir_path in [images_dir, frames_dir, colmap_dir]:\n",
    "            if os.path.exists(dir_path):\n",
    "                print(f\"Clearing directory: {dir_path}\")\n",
    "                for item in os.listdir(dir_path):\n",
    "                    item_path = os.path.join(dir_path, item)\n",
    "                    try:\n",
    "                        if os.path.isfile(item_path):\n",
    "                            os.unlink(item_path)\n",
    "                        elif os.path.isdir(item_path):\n",
    "                            import shutil\n",
    "                            shutil.rmtree(item_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error while clearing {item_path}: {e}\")\n",
    "    \n",
    "    # Phase 0: Download data from S3\n",
    "    print(\"\\n=== Phase 0: Download Data from S3 ===\")\n",
    "    video_path = download_video_from_s3(\n",
    "        bucket_name=bucket_name,\n",
    "        video_prefix=video_prefix,\n",
    "        video_filename=video_filename,\n",
    "        zip_filename=zip_filename,\n",
    "        fallback_images_prefix=fallback_images_prefix,\n",
    "        fallback_cameras_prefix=fallback_cameras_prefix\n",
    "    )\n",
    "    \n",
    "    # Check if we have a video or images\n",
    "    if video_path and os.path.exists(video_path):\n",
    "        print(f\"Using video file: {video_path}\")\n",
    "        # Phase 1: Frame extraction\n",
    "        print(\"\\n=== Phase 1: Frame Extraction ===\")\n",
    "        os.makedirs(frames_dir, exist_ok=True)\n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        \n",
    "        extract_frames(video_path, frames_dir)\n",
    "        \n",
    "        # Clear images directory before copying new frames\n",
    "        for file in os.listdir(images_dir):\n",
    "            file_path = os.path.join(images_dir, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "        \n",
    "        copy_to_images(frames_dir, images_dir)\n",
    "        \n",
    "        # Debug: Check what's in the images directory\n",
    "        print(f\"\\nDebug: Checking images directory after frame extraction\")\n",
    "        image_files = os.listdir(images_dir)\n",
    "        print(f\"Found {len(image_files)} files in {images_dir}\")\n",
    "        if len(image_files) > 0:\n",
    "            print(f\"First few images: {image_files[:5]}\")\n",
    "    else:\n",
    "        print(\"No video found, using downloaded images directly\")\n",
    "        # Check if we have images\n",
    "        if not os.listdir(images_dir):\n",
    "            print(\"❌ No images found. Please check S3 access and try again.\")\n",
    "            return\n",
    "    \n",
    "    # Phase 2: COLMAP reconstruction\n",
    "    print(\"\\n=== Phase 2: COLMAP Reconstruction ===\")\n",
    "    print(f\"Debug: About to call run_colmap_pipeline() at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    try:\n",
    "        timing_info = run_colmap_pipeline()\n",
    "        print(f\"Debug: run_colmap_pipeline() completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in COLMAP pipeline: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    # Phase 3: YOLO object detection\n",
    "    print(\"\\n=== Phase 3: Object Detection ===\")\n",
    "    try:\n",
    "        run_yolo_detection()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in YOLO detection: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    # Phase 4: 2D to 3D projection\n",
    "    print(f\"\\n=== Phase 4: 2D to 3D Projection ({target_label}) ===\")\n",
    "    try:\n",
    "        project_detections_to_3d(target_label)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in 2D to 3D projection: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    # Phase 5: Create detection sphere\n",
    "    print(f\"\\n=== Phase 5: Create Detection Sphere ===\")\n",
    "    try:\n",
    "        create_detection_sphere(target_label)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in detection sphere creation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    print(\"\\n=== Workflow Complete! ===\")\n",
    "    print(f\"Results are in: {os.path.join(base_dir, 'results')}\")\n",
    "    \n",
    "    # Return timing information for potential analysis\n",
    "    return timing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556334db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import shutil\n",
    "\n",
    "def extract_frames(video_path, output_dir, frame_rate=3):\n",
    "    \"\"\"\n",
    "    Extract frames from a video file\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to the video file\n",
    "        output_dir: Directory to save extracted frames\n",
    "        frame_rate: Number of frames to extract per second\n",
    "    \"\"\"\n",
    "    print(f\"Extracting frames from {video_path} to {output_dir}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "    \n",
    "    print(f\"Video properties: {fps:.2f} fps, {total_frames} frames, {duration:.2f} seconds\")\n",
    "    \n",
    "    # Calculate frame interval based on desired frame rate\n",
    "    frame_interval = int(fps / frame_rate)\n",
    "    if frame_interval < 1:\n",
    "        frame_interval = 1\n",
    "    \n",
    "    # Extract frames\n",
    "    count = 0\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Save frame at specified intervals\n",
    "        if count % frame_interval == 0:\n",
    "            frame_path = os.path.join(output_dir, f\"frame_{frame_count:04d}.jpg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            frame_count += 1\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    video.release()\n",
    "    print(f\"Extracted {frame_count} frames from video\")\n",
    "    return True\n",
    "\n",
    "def copy_to_images(frames_dir, images_dir):\n",
    "    \"\"\"\n",
    "    Copy extracted frames to images directory\n",
    "    \n",
    "    Args:\n",
    "        frames_dir: Directory containing extracted frames\n",
    "        images_dir: Directory to copy frames to\n",
    "    \"\"\"\n",
    "    print(f\"Copying frames from {frames_dir} to {images_dir}\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    \n",
    "    # Get list of frame files\n",
    "    frame_files = [f for f in os.listdir(frames_dir) if f.endswith('.jpg')]\n",
    "    \n",
    "    # Copy each frame to images directory\n",
    "    for frame_file in frame_files:\n",
    "        src_path = os.path.join(frames_dir, frame_file)\n",
    "        dst_path = os.path.join(images_dir, frame_file)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    \n",
    "    print(f\"Copied {len(frame_files)} frames to images directory\")\n",
    "    return True\n",
    "\n",
    "def run_colmap_pipeline():\n",
    "    \"\"\"Run COLMAP reconstruction pipeline\"\"\"\n",
    "    print(\"Running COLMAP reconstruction...\")\n",
    "    # This would contain the actual COLMAP commands\n",
    "    # For now, we'll just simulate it\n",
    "    print(\"COLMAP reconstruction completed\")\n",
    "    return True\n",
    "\n",
    "def run_yolo_detection():\n",
    "    \"\"\"Run YOLO object detection on images\"\"\"\n",
    "    print(\"Running YOLO object detection...\")\n",
    "    # This would contain the actual YOLO detection code\n",
    "    # For now, we'll just simulate it\n",
    "    print(\"YOLO detection completed\")\n",
    "    return True\n",
    "\n",
    "def project_detections_to_3d(target_label):\n",
    "    \"\"\"Project 2D detections to 3D space\"\"\"\n",
    "    print(f\"Projecting {target_label} detections to 3D...\")\n",
    "    # This would contain the actual projection code\n",
    "    # For now, we'll just simulate it\n",
    "    print(\"Projection completed\")\n",
    "    return True\n",
    "\n",
    "def create_detection_sphere(target_label):\n",
    "    \"\"\"Create detection sphere for visualization\"\"\"\n",
    "    print(f\"Creating detection sphere for {target_label}...\")\n",
    "    # This would contain the actual sphere creation code\n",
    "    # For now, we'll just simulate it\n",
    "    print(\"Detection sphere created\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f36ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second cell - Create directory structure\n",
    "# Create subdirectories\n",
    "subdirs = [\n",
    "    \"video\",           # For input video\n",
    "    \"images\",          # Full image set (frames or photos)\n",
    "    \"images_down\",     # Optional: downselected images for speed\n",
    "    \"colmap\",          # COLMAP outputs\n",
    "    \"detections\",      # YOLO outputs + detections.json\n",
    "    \"results\",         # Final outputs (fused.ply, detections_3d.json)\n",
    "    \"scripts\"          # Helper scripts\n",
    "]\n",
    "\n",
    "for subdir in subdirs:\n",
    "    os.makedirs(os.path.join(base_dir, subdir), exist_ok=True)\n",
    "\n",
    "print(\"✅ Directory structure created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Download data from S3 bucket\n",
    "import boto3\n",
    "import os\n",
    "import warnings\n",
    "import urllib3\n",
    "import zipfile\n",
    "\n",
    "# Suppress SSL warnings\n",
    "warnings.filterwarnings('ignore', category=urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def download_from_s3(bucket_name, prefix, local_dir, file_limit=None):\n",
    "    \"\"\"\n",
    "    Download files from S3 bucket to local directory\n",
    "    Args:\n",
    "        bucket_name: S3 bucket name\n",
    "        prefix: Path prefix in the bucket\n",
    "        local_dir: Local directory to save files\n",
    "        file_limit: Maximum number of files to download (None for all)\n",
    "    \"\"\"\n",
    "    # Configure S3 client\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        region_name='us-gov-west-1',\n",
    "        verify=False\n",
    "    )\n",
    "    \n",
    "    # Create local directory if it doesn't exist\n",
    "    os.makedirs(local_dir, exist_ok=True)\n",
    "    \n",
    "    # List objects in the bucket with the given prefix\n",
    "    print(f\"Listing objects in s3://{bucket_name}/{prefix}\")\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix=prefix\n",
    "    )\n",
    "    \n",
    "    if 'Contents' not in response:\n",
    "        print(f\"No objects found in s3://{bucket_name}/{prefix}\")\n",
    "        return []\n",
    "    \n",
    "    # Get the list of objects\n",
    "    objects = response['Contents']\n",
    "    if file_limit:\n",
    "        objects = objects[:file_limit]\n",
    "    \n",
    "    # Download each object\n",
    "    downloaded_files = []\n",
    "    for obj in objects:\n",
    "        key = obj['Key']\n",
    "        filename = os.path.basename(key)\n",
    "        local_path = os.path.join(local_dir, filename)\n",
    "        \n",
    "        # Skip if file already exists\n",
    "        if os.path.exists(local_path) and os.path.getsize(local_path) == obj['Size']:\n",
    "            print(f\"Skipping {filename} (already exists)\")\n",
    "            downloaded_files.append(local_path)\n",
    "            continue\n",
    "        \n",
    "        # Download the file\n",
    "        print(f\"Downloading {key} ({obj['Size']/1024/1024:.2f} MB)\")\n",
    "        s3_client.download_file(\n",
    "            bucket_name,\n",
    "            key,\n",
    "            local_path\n",
    "        )\n",
    "        downloaded_files.append(local_path)\n",
    "    \n",
    "    print(f\"Downloaded {len(downloaded_files)} files to {local_dir}\")\n",
    "    return downloaded_files\n",
    "\n",
    "def extract_zip_file(zip_path, extract_to):\n",
    "    \"\"\"Extract contents of a zip file\"\"\"\n",
    "    print(f\"Extracting {zip_path} to {extract_to}\")\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    \n",
    "    print(f\"Extracted zip contents to {extract_to}\")\n",
    "    return extract_to\n",
    "\n",
    "def download_video_from_s3(bucket_name='hiitsd-mt-visualdigitaltwin-conf-room', \n",
    "                          video_prefix='Conference-Room-14OCT2025-Camera/',\n",
    "                          video_filename='conf_room_14OCT-CAM.MOV',\n",
    "                          zip_filename='confroom_14OCT2025-CAM.zip',\n",
    "                          fallback_images_prefix='post_model_dataset_jpgs/jpgs/jpgs/',\n",
    "                          fallback_cameras_prefix='post_model_dataset/cameras/cameras/'):\n",
    "    \"\"\"\n",
    "    Download video file from S3 bucket\n",
    "    \n",
    "    Args:\n",
    "        bucket_name: S3 bucket name\n",
    "        video_prefix: Path prefix for the video files\n",
    "        video_filename: Name of the video file to download\n",
    "        zip_filename: Name of the zip file to download as fallback\n",
    "        fallback_images_prefix: Path prefix for fallback images\n",
    "        fallback_cameras_prefix: Path prefix for fallback camera data\n",
    "    \"\"\"\n",
    "    video_dir = os.path.join(base_dir, \"video\")\n",
    "    \n",
    "    try:\n",
    "        # List all files in the prefix\n",
    "        s3_client = boto3.client(\n",
    "            's3',\n",
    "            region_name='us-gov-west-1',\n",
    "            verify=False\n",
    "        )\n",
    "        \n",
    "        response = s3_client.list_objects_v2(\n",
    "            Bucket=bucket_name,\n",
    "            Prefix=video_prefix\n",
    "        )\n",
    "        \n",
    "        if 'Contents' not in response:\n",
    "            print(f\"No objects found in s3://{bucket_name}/{video_prefix}\")\n",
    "            return None\n",
    "        \n",
    "        # First try to download the MOV file\n",
    "        mov_key = video_prefix + video_filename\n",
    "        mov_path = os.path.join(video_dir, video_filename)\n",
    "        \n",
    "        try:\n",
    "            print(f\"Attempting to download video file: {mov_key}\")\n",
    "            os.makedirs(video_dir, exist_ok=True)\n",
    "            s3_client.download_file(bucket_name, mov_key, mov_path)\n",
    "            print(f\"Successfully downloaded video to {mov_path}\")\n",
    "            return mov_path\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading video file: {e}\")\n",
    "            \n",
    "        # If video fails, try the ZIP file\n",
    "        zip_key = video_prefix + zip_filename\n",
    "        zip_path = os.path.join(video_dir, zip_filename)\n",
    "        \n",
    "        try:\n",
    "            print(f\"Attempting to download ZIP file: {zip_key}\")\n",
    "            os.makedirs(video_dir, exist_ok=True)\n",
    "            s3_client.download_file(bucket_name, zip_key, zip_path)\n",
    "            print(f\"Successfully downloaded ZIP to {zip_path}\")\n",
    "            \n",
    "            # Extract the ZIP file\n",
    "            extract_dir = os.path.join(base_dir, \"extracted\")\n",
    "            extract_zip_file(zip_path, extract_dir)\n",
    "            \n",
    "            # Look for video files in the extracted directory\n",
    "            for root, _, files in os.walk(extract_dir):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('.mov', '.mp4')):\n",
    "                        video_path = os.path.join(root, file)\n",
    "                        print(f\"Found video in ZIP: {video_path}\")\n",
    "                        return video_path\n",
    "            \n",
    "            print(\"No video files found in the ZIP archive\")\n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading ZIP file: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing S3: {e}\")\n",
    "    \n",
    "    # If all else fails, try to download images directly\n",
    "    print(\"Downloading images from fallback dataset...\")\n",
    "    images_dir = os.path.join(base_dir, \"images\")\n",
    "    download_from_s3(\n",
    "        bucket_name,\n",
    "        fallback_images_prefix,\n",
    "        images_dir,\n",
    "        file_limit=100  # Limit to 100 images for testing\n",
    "    )\n",
    "    \n",
    "    # Also download camera data if needed\n",
    "    cameras_dir = os.path.join(base_dir, \"cameras\")\n",
    "    download_from_s3(\n",
    "        bucket_name,\n",
    "        fallback_cameras_prefix,\n",
    "        cameras_dir,\n",
    "        file_limit=100\n",
    "    )\n",
    "    \n",
    "    return None  # No video downloaded, but images are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "def run_colmap_pipeline():\n",
    "    \"\"\"Run the complete COLMAP pipeline with timing information and GPU acceleration\"\"\"\n",
    "    # Start timing the entire pipeline\n",
    "    pipeline_start_time = time.time()\n",
    "    print(f\"Starting COLMAP pipeline at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"Using NVIDIA L4 GPU for acceleration\")\n",
    "    \n",
    "    colmap_dir = os.path.join(base_dir, \"colmap_cropped\")\n",
    "    images_dir = os.path.join(base_dir, \"cropped_frames\")\n",
    "    sparse_dir = os.path.join(colmap_dir, \"sparse\")\n",
    "    dense_dir = os.path.join(colmap_dir, \"dense\")\n",
    "    results_dir = os.path.join(base_dir, \"results_cropped\")\n",
    "    \n",
    "    os.makedirs(colmap_dir, exist_ok=True)\n",
    "    os.makedirs(sparse_dir, exist_ok=True)\n",
    "    os.makedirs(dense_dir, exist_ok=True)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Define the full path to COLMAP executable\n",
    "    colmap_exe = r\"C:\\Users\\zzballabe1\\Documents\\COLMAP\\COLMAP.bat\"\n",
    "    \n",
    "    # Dictionary to store timing information\n",
    "    timing_info = {}\n",
    "    \n",
    "    # 1. Feature extraction with GPU\n",
    "    print(f\"\\nStep 1: Feature extraction - Started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    step1_start = time.time()\n",
    "    cmd = [\n",
    "        colmap_exe, \"feature_extractor\",\n",
    "        \"--database_path\", os.path.join(colmap_dir, \"database.db\"),\n",
    "        \"--image_path\", images_dir,\n",
    "        \"--SiftExtraction.use_gpu\", \"1\",\n",
    "        \"--SiftExtraction.gpu_index\", \"0\",\n",
    "        \"--SiftExtraction.max_num_features\", \"8192\",  # Default is 8192, increase if needed\n",
    "        \"--SiftExtraction.first_octave\", \"-1\"         # Start at a lower octave to detect more features\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "    step1_time = time.time() - step1_start\n",
    "    timing_info['feature_extraction'] = step1_time\n",
    "    print(f\"Step 1: Feature extraction - Completed in {step1_time:.2f} seconds ({step1_time/60:.2f} minutes)\")\n",
    "    \n",
    "    # 2. Feature matching with GPU\n",
    "    print(f\"\\nStep 2: Feature matching - Started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    step2_start = time.time()\n",
    "\n",
    "    cmd = [\n",
    "        colmap_exe, \"exhaustive_matcher\",\n",
    "        \"--database_path\", os.path.join(colmap_dir, \"database.db\"),\n",
    "        \"--SiftMatching.use_gpu\", \"1\",\n",
    "        \"--SiftMatching.gpu_index\", \"0\"\n",
    "    ]\n",
    "    \n",
    "    subprocess.run(cmd)\n",
    "    step2_time = time.time() - step2_start\n",
    "    timing_info['feature_matching'] = step2_time\n",
    "    print(f\"Step 2: Feature matching - Completed in {step2_time:.2f} seconds ({step2_time/60:.2f} minutes)\")\n",
    "    \n",
    "    # 3. Sparse reconstruction\n",
    "    print(f\"\\nStep 3: Sparse reconstruction - Started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    step3_start = time.time()\n",
    "    cmd = [\n",
    "        colmap_exe, \"mapper\",\n",
    "        \"--database_path\", os.path.join(colmap_dir, \"database.db\"),\n",
    "        \"--image_path\", images_dir,\n",
    "        \"--output_path\", sparse_dir\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "    step3_time = time.time() - step3_start\n",
    "    timing_info['sparse_reconstruction'] = step3_time\n",
    "    print(f\"Step 3: Sparse reconstruction - Completed in {step3_time:.2f} seconds ({step3_time/60:.2f} minutes)\")\n",
    "    \n",
    "    # 4. Image undistortion\n",
    "    print(f\"\\nStep 4: Image undistortion - Started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    step4_start = time.time()\n",
    "    cmd = [\n",
    "        colmap_exe, \"image_undistorter\",\n",
    "        \"--image_path\", images_dir,\n",
    "        \"--input_path\", os.path.join(sparse_dir, \"0\"),\n",
    "        \"--output_path\", dense_dir,\n",
    "        \"--output_type\", \"COLMAP\"\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "    step4_time = time.time() - step4_start\n",
    "    timing_info['image_undistortion'] = step4_time\n",
    "    print(f\"Step 4: Image undistortion - Completed in {step4_time:.2f} seconds ({step4_time/60:.2f} minutes)\")\n",
    "    \n",
    "    # 5. Patch match stereo with GPU\n",
    "    print(f\"\\nStep 5: Patch match stereo - Started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    step5_start = time.time()\n",
    "    cmd = [\n",
    "        colmap_exe, \"patch_match_stereo\",\n",
    "        \"--workspace_path\", dense_dir,\n",
    "        \"--PatchMatchStereo.gpu_index\", \"0\"\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "    step5_time = time.time() - step5_start\n",
    "    timing_info['patch_match_stereo'] = step5_time\n",
    "    print(f\"Step 5: Patch match stereo - Completed in {step5_time:.2f} seconds ({step5_time/60:.2f} minutes)\")\n",
    "    \n",
    "    # 6. Stereo fusion\n",
    "    print(f\"\\nStep 6: Stereo fusion - Started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    step6_start = time.time()\n",
    "    cmd = [\n",
    "        colmap_exe, \"stereo_fusion\",\n",
    "        \"--workspace_path\", dense_dir,\n",
    "        \"--output_path\", os.path.join(results_dir, \"fused.ply\")\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "    step6_time = time.time() - step6_start\n",
    "    timing_info['stereo_fusion'] = step6_time\n",
    "    print(f\"Step 6: Stereo fusion - Completed in {step6_time:.2f} seconds ({step6_time/60:.2f} minutes)\")\n",
    "    \n",
    "    # 7. Export model to TXT format\n",
    "    print(f\"\\nStep 7: Exporting model to TXT format - Started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    model_txt_dir = os.path.join(colmap_dir, \"model_txt\", \"0\")\n",
    "    os.makedirs(os.path.dirname(model_txt_dir), exist_ok=True)\n",
    "    step7_start = time.time()\n",
    "    cmd = [\n",
    "        colmap_exe, \"model_converter\",\n",
    "        \"--input_path\", os.path.join(sparse_dir, \"0\"),\n",
    "        \"--output_path\", model_txt_dir,\n",
    "        \"--output_type\", \"TXT\"\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "    step7_time = time.time() - step7_start\n",
    "    timing_info['model_export'] = step7_time\n",
    "    print(f\"Step 7: Model export - Completed in {step7_time:.2f} seconds ({step7_time/60:.2f} minutes)\")\n",
    "    \n",
    "    # Calculate total pipeline time\n",
    "    total_pipeline_time = time.time() - pipeline_start_time\n",
    "    timing_info['total_pipeline_time'] = total_pipeline_time\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"COLMAP PIPELINE TIMING SUMMARY (GPU-ACCELERATED)\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Step 1: Feature extraction:    {timing_info['feature_extraction']:.2f} seconds ({timing_info['feature_extraction']/60:.2f} minutes)\")\n",
    "    print(f\"Step 2: Feature matching:      {timing_info['feature_matching']:.2f} seconds ({timing_info['feature_matching']/60:.2f} minutes)\")\n",
    "    print(f\"Step 3: Sparse reconstruction: {timing_info['sparse_reconstruction']:.2f} seconds ({timing_info['sparse_reconstruction']/60:.2f} minutes)\")\n",
    "    print(f\"Step 4: Image undistortion:    {timing_info['image_undistortion']:.2f} seconds ({timing_info['image_undistortion']/60:.2f} minutes)\")\n",
    "    print(f\"Step 5: Patch match stereo:    {timing_info['patch_match_stereo']:.2f} seconds ({timing_info['patch_match_stereo']/60:.2f} minutes)\")\n",
    "    print(f\"Step 6: Stereo fusion:         {timing_info['stereo_fusion']:.2f} seconds ({timing_info['stereo_fusion']/60:.2f} minutes)\")\n",
    "    print(f\"Step 7: Model export:          {timing_info['model_export']:.2f} seconds ({timing_info['model_export']/60:.2f} minutes)\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"TOTAL PIPELINE TIME:           {total_pipeline_time:.2f} seconds ({total_pipeline_time/60:.2f} minutes)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Final completion messages\n",
    "    print(\"\\n✅ COLMAP pipeline completed with GPU acceleration\")\n",
    "    print(f\"✅ Dense point cloud saved to: {os.path.join(results_dir, 'fused.ply')}\")\n",
    "    print(f\"✅ Model exported to TXT format: {model_txt_dir}\")\n",
    "    \n",
    "    # Return timing information for potential further analysis\n",
    "    return timing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b36e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fifth cell - YOLO detection function\n",
    "def run_yolo_detection():\n",
    "    print(\"Running yolo detection\")\n",
    "    \"\"\"Run YOLOv8 detection on images and save results\"\"\"\n",
    "    img_dir = os.path.join(base_dir, \"images\")\n",
    "    out_dir = os.path.join(base_dir, \"detections\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    # Check if model exists locally first\n",
    "    model_path = os.path.join(base_dir, \"yolov8m.pt\")\n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"Model not found locally, downloading with SSL verification disabled...\")\n",
    "        import requests\n",
    "        import warnings\n",
    "        import urllib3\n",
    "        # Suppress SSL warnings\n",
    "        warnings.filterwarnings('ignore', category=urllib3.exceptions.InsecureRequestWarning)\n",
    "        # Download the model with SSL verification disabled\n",
    "        url = \"https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt\"\n",
    "        response = requests.get(url, verify=False, stream=True)\n",
    "        with open(model_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"Model downloaded to {model_path}\")\n",
    "    \n",
    "    # Install YOLOv8 if not already installed\n",
    "    try:\n",
    "        from ultralytics import YOLO\n",
    "    except ImportError:\n",
    "        print(\"Installing ultralytics...\")\n",
    "        !pip install ultralytics\n",
    "        from ultralytics import YOLO\n",
    "    \n",
    "    # Load YOLOv8 model from local file\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # Run inference\n",
    "    results = model.predict(\n",
    "        source=img_dir,\n",
    "        conf=0.4,\n",
    "        save=True,\n",
    "        project=out_dir,\n",
    "        name=\"yolo_out\",\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Pack results into a single JSON\n",
    "    det_json = {}\n",
    "    for r in results:\n",
    "        img_name = os.path.basename(r.path)\n",
    "        per_image = []\n",
    "        for b in r.boxes:\n",
    "            xyxy = b.xyxy[0].tolist()  # [x1,y1,x2,y2]\n",
    "            cls = int(b.cls[0].item())\n",
    "            conf = float(b.conf[0].item())\n",
    "            per_image.append({\n",
    "                \"label\": model.names[cls],\n",
    "                \"bbox\": [float(xyxy[0]), float(xyxy[1]), float(xyxy[2]), float(xyxy[3])],\n",
    "                \"confidence\": conf\n",
    "            })\n",
    "        det_json[img_name] = per_image\n",
    "    \n",
    "    out_json = os.path.join(out_dir, \"detections.json\")\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump(det_json, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Wrote {out_json}\")\n",
    "    print(f\"✅ Annotated images: {os.path.join(out_dir, 'yolo_out')}\")\n",
    "    return det_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb9c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sixth cell - 2D to 3D projection functions\n",
    "def load_points3D_txt(path):\n",
    "    pts = {}\n",
    "    with open(os.path.join(path, \"points3D.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\") or not line.strip():\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            pid = int(parts[0])\n",
    "            x, y, z = map(float, parts[1:4])\n",
    "            pts[pid] = (x, y, z)\n",
    "    return pts\n",
    "\n",
    "def load_images_txt(path):\n",
    "    \"\"\"\n",
    "    Returns dict: name -> {\"id\": int, \"xys\": Nx2 float array, \"pids\": Nx int array}\n",
    "    Only what we need: the 2D points (x,y) and their linked 3D point IDs.\n",
    "    \"\"\"\n",
    "    name_to_data = {}\n",
    "    with open(os.path.join(path, \"images.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [ln.strip() for ln in f if ln.strip()]\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if lines[i].startswith(\"#\"):\n",
    "            i += 1\n",
    "            continue\n",
    "        head = lines[i].split()  # IMAGE_ID qw qx qy qz tx ty tz CAMERA_ID NAME\n",
    "        if len(head) < 10:\n",
    "            i += 1\n",
    "            continue\n",
    "        img_id = int(head[0])\n",
    "        name = head[9]\n",
    "        i += 1\n",
    "        if i >= len(lines):\n",
    "            break\n",
    "        \n",
    "        xy_pid_line = lines[i]  # x y POINT3D_ID repeating\n",
    "        i += 1\n",
    "        \n",
    "        arr = xy_pid_line.split()\n",
    "        xs, ys, pids = [], [], []\n",
    "        for k in range(0, len(arr), 3):\n",
    "            try:\n",
    "                x = float(arr[k]); y = float(arr[k+1]); pid = int(arr[k+2])\n",
    "            except Exception:\n",
    "                break\n",
    "            xs.append(x); ys.append(y); pids.append(pid)\n",
    "        \n",
    "        xys = np.stack([np.array(xs), np.array(ys)], axis=1) if xs else np.zeros((0,2))\n",
    "        pids = np.array(pids, dtype=np.int64) if pids else np.zeros((0,), dtype=np.int64)\n",
    "        name_to_data[name] = {\"id\": img_id, \"xys\": xys, \"pids\": pids}\n",
    "    return name_to_data\n",
    "\n",
    "def bbox_filter(xys, pids, bbox, min_pts=6):\n",
    "    \"\"\" Return 3D point IDs whose 2D projections fall inside bbox [x1,y1,x2,y2]. \"\"\"\n",
    "    if xys.shape[0] == 0:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    mask = (xys[:,0] >= x1) & (xys[:,0] <= x2) & (xys[:,1] >= y1) & (xys[:,1] <= y2) & (pids != -1)\n",
    "    sel = pids[mask]\n",
    "    if sel.size < min_pts:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    return sel\n",
    "\n",
    "def robust_center(points_xyz):\n",
    "    \"\"\" Median is robust against outliers. \"\"\"\n",
    "    pts = np.array(points_xyz, dtype=float)\n",
    "    if pts.shape[0] == 0:\n",
    "        return None\n",
    "    return np.median(pts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seventh cell - 2D to 3D projection main function\n",
    "def project_detections_to_3d(target_label=\"dog\"):\n",
    "    \"\"\"Project 2D detections to 3D space\"\"\"\n",
    "    \n",
    "    print(\"Project detection_to_3d\")\n",
    "\n",
    "    # Install Open3D if not already installed\n",
    "    try:\n",
    "        import open3d as o3d\n",
    "    except ImportError:\n",
    "        print(\"Installing open3d...\")\n",
    "        !pip install open3d --trusted-host pypi.org --trusted-host files.pythonhosted.org\n",
    "        import open3d as o3d\n",
    "    \n",
    "    txt_model = os.path.join(base_dir, \"colmap\", \"model_txt\", \"0\")\n",
    "    dets_json = os.path.join(base_dir, \"detections\", \"detections.json\")\n",
    "    fused_ply = os.path.join(base_dir, \"results\", \"fused.ply\")\n",
    "    out_ply = os.path.join(base_dir, \"results\", f\"{target_label}_markers.ply\")\n",
    "    out_json = os.path.join(base_dir, \"results\", f\"{target_label}_detections_3d.json\")\n",
    "    \n",
    "    os.makedirs(os.path.dirname(out_ply), exist_ok=True)\n",
    "    \n",
    "    pts3d = load_points3D_txt(txt_model)\n",
    "    imgs = load_images_txt(txt_model)\n",
    "    \n",
    "    with open(dets_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        dets = json.load(f)\n",
    "    \n",
    "    centers = []\n",
    "    det3d_records = []\n",
    "    \n",
    "    for img_name, det_list in dets.items():\n",
    "        # normalize name if detections used full paths\n",
    "        base = os.path.basename(img_name)\n",
    "        key = img_name if img_name in imgs else (base if base in imgs else None)\n",
    "        if key is None:\n",
    "            continue\n",
    "        \n",
    "        xys = imgs[key][\"xys\"]\n",
    "        pids = imgs[key][\"pids\"]\n",
    "        \n",
    "        for det in det_list:\n",
    "            if det[\"label\"].lower() != target_label.lower():\n",
    "                continue\n",
    "            x1, y1, x2, y2 = det[\"bbox\"]\n",
    "            sel_pids = bbox_filter(xys, pids, (x1, y1, x2, y2), min_pts=6)\n",
    "            if sel_pids.size == 0:\n",
    "                continue\n",
    "            \n",
    "            xyzs = [pts3d[pid] for pid in sel_pids if pid in pts3d]\n",
    "            if not xyzs:\n",
    "                continue\n",
    "            \n",
    "            center = robust_center(xyzs)\n",
    "            if center is None:\n",
    "                continue\n",
    "            \n",
    "            centers.append(center.tolist())\n",
    "            det3d_records.append({\n",
    "                \"image\": key,\n",
    "                \"label\": target_label,\n",
    "                \"bbox\": det[\"bbox\"],\n",
    "                \"num_points_3d\": len(xyzs),\n",
    "                \"center_xyz\": center.tolist()\n",
    "            })\n",
    "    \n",
    "    with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"detections_3d\": det3d_records}, f, indent=2)\n",
    "    print(f\"✅ Wrote {out_json}  ({len(det3d_records)} {target_label} instances)\")\n",
    "    \n",
    "    if not centers:\n",
    "        print(f\"⚠️ No {target_label} centers estimated. Check that YOLO produced '{target_label}' detections and image names match COLMAP.\")\n",
    "        return\n",
    "    \n",
    "    # markers cloud (red)\n",
    "    markers = o3d.geometry.PointCloud()\n",
    "    markers.points = o3d.utility.Vector3dVector(np.array(centers))\n",
    "    colors = np.tile(np.array([[1.0, 0.0, 0.0]]), (len(centers), 1))\n",
    "    markers.colors = o3d.utility.Vector3dVector(colors)\n",
    "    o3d.io.write_point_cloud(out_ply, markers)\n",
    "    print(f\"✅ Wrote {out_ply}\")\n",
    "    \n",
    "    # quick viewer\n",
    "    if os.path.exists(fused_ply):\n",
    "        scene = o3d.io.read_point_cloud(fused_ply)\n",
    "        if len(np.asarray(scene.points)) > 0:\n",
    "            scene.colors = o3d.utility.Vector3dVector(\n",
    "                np.tile(np.array([[0.8, 0.8, 0.8]]), (len(scene.points), 1))\n",
    "            )\n",
    "        o3d.visualization.draw_geometries([scene, markers])\n",
    "    else:\n",
    "        o3d.visualization.draw_geometries([markers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26116c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eighth cell - Create detection sphere\n",
    "print(\"Running create_detection_sphere\")\n",
    "\n",
    "def create_detection_sphere(target_label=\"dog\", eps=0.40, padding=0.10, min_radius=0.15, max_radius=1.00, resolution=48):\n",
    "    \"\"\"Merge nearby detections into one cluster and export ONE sphere that encloses them.\"\"\"\n",
    "\n",
    "    # Install Open3D if not already installed\n",
    "    try:\n",
    "        import open3d as o3d\n",
    "    except ImportError:\n",
    "        print(\"Installing open3d...\")\n",
    "        !pip install open3d\n",
    "        import open3d as o3d\n",
    "    \n",
    "    in_json = os.path.join(base_dir, \"results\", f\"{target_label}_detections_3d.json\")\n",
    "    out_ply = os.path.join(base_dir, \"results\", f\"{target_label}_sphere_single.ply\")\n",
    "    fused_ply = os.path.join(base_dir, \"results\", \"fused.ply\")\n",
    "    \n",
    "    # Greedy radius clustering\n",
    "    def cluster_points(points, eps=0.40):\n",
    "        \"\"\"Greedy radius clustering. eps in meters. Returns list of clusters (each a list of indices).\"\"\"\n",
    "        if len(points) == 0:\n",
    "            return []\n",
    "        pts = np.asarray(points, dtype=float)\n",
    "        n = pts.shape[0]\n",
    "        used = np.zeros(n, dtype=bool)\n",
    "        clusters = []\n",
    "        for i in range(n):\n",
    "            if used[i]:\n",
    "                continue\n",
    "            center = pts[i]\n",
    "            d = np.linalg.norm(pts - center, axis=1)\n",
    "            members = np.where(d <= eps)[0]\n",
    "            used[members] = True\n",
    "            clusters.append(members.tolist())\n",
    "        return clusters\n",
    "    \n",
    "    # load 3D centers\n",
    "    with open(in_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        dets = json.load(f).get(\"detections_3d\", [])\n",
    "    centers = [d[\"center_xyz\"] for d in dets]\n",
    "    if not centers:\n",
    "        print(f\"⚠️ No centers found. Run projection to 3D first.\")\n",
    "        return\n",
    "    \n",
    "    # cluster & pick the largest group\n",
    "    clusters = cluster_points(centers, eps=eps)\n",
    "    # if everything is very close, you'll likely get a single cluster already\n",
    "    best = max(clusters, key=len)\n",
    "    P = np.asarray([centers[i] for i in best], dtype=float)\n",
    "    \n",
    "    # sphere center = cluster centroid (or median for robustness)\n",
    "    center = np.median(P, axis=0)\n",
    "    \n",
    "    # sphere radius = max distance to center + padding\n",
    "    dists = np.linalg.norm(P - center[None, :], axis=1)\n",
    "    r = float(np.max(dists)) + float(padding)\n",
    "    r = float(np.clip(r, min_radius, max_radius))\n",
    "    \n",
    "    # build sphere mesh\n",
    "    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=r, resolution=resolution)\n",
    "    sphere.compute_vertex_normals()\n",
    "    sphere.paint_uniform_color([1.0, 0.0, 0.0])  # red\n",
    "    sphere.translate(center.tolist())\n",
    "    \n",
    "    os.makedirs(os.path.dirname(out_ply), exist_ok=True)\n",
    "    o3d.io.write_triangle_mesh(out_ply, sphere)\n",
    "    print(f\"✅ Wrote {out_ply}  (center={center.tolist()}, radius={r:.3f} m, cluster_size={len(best)})\")\n",
    "    \n",
    "    # quick preview (optional)\n",
    "    geoms = []\n",
    "    if os.path.exists(fused_ply):\n",
    "        cloud = o3d.io.read_point_cloud(fused_ply)\n",
    "        geoms.append(cloud)\n",
    "    geoms.append(sphere)\n",
    "    if geoms:\n",
    "        o3d.visualization.draw_geometries(geoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee995a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ninth cell - Complete workflow execution\n",
    "print(\"Running run_complete_workflow\")\n",
    "print(\"=== Visual Digital Twin Workflow ===\")\n",
    "\n",
    "def run_complete_workflow(target_label=\"dog\", video_path=None):\n",
    "    \"\"\"Run the complete workflow from video to 3D detection\"\"\"\n",
    "    \n",
    "    # Check if video exists\n",
    "    if video_path is None:\n",
    "        video_path = os.path.join(base_dir, \"video\", \"room.MP4\")\n",
    "    \n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"❌ Video not found: {video_path}\")\n",
    "        print(\"Please place your video in the video directory first.\")\n",
    "        return\n",
    "    \n",
    "    # Phase 1: Frame extraction\n",
    "    print(\"\\n=== Phase 1: Frame Extraction ===\")\n",
    "    frames_dir = os.path.join(base_dir, \"frames\")\n",
    "    images_dir = os.path.join(base_dir, \"images\")\n",
    "    extract_frames(video_path, frames_dir)\n",
    "    copy_to_images(frames_dir, images_dir)\n",
    "    \n",
    "    # Phase 2: COLMAP reconstruction\n",
    "    print(\"\\n=== Phase 2: COLMAP Reconstruction ===\")\n",
    "    run_colmap_pipeline()\n",
    "    \n",
    "    # Phase 3: YOLO object detection\n",
    "    print(\"\\n=== Phase 3: Object Detection ===\")\n",
    "    run_yolo_detection()\n",
    "    \n",
    "    # Phase 4: 2D to 3D projection\n",
    "    print(f\"\\n=== Phase 4: 2D to 3D Projection ({target_label}) ===\")\n",
    "    project_detections_to_3d(target_label)\n",
    "    \n",
    "    # Phase 5: Create detection sphere\n",
    "    print(f\"\\n=== Phase 5: Create Detection Sphere ===\")\n",
    "    create_detection_sphere(target_label)\n",
    "    \n",
    "    print(\"\\n=== Workflow Complete! ===\")\n",
    "    print(f\"Results are in: {os.path.join(base_dir, 'results')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad45beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "run_complete_workflow_with_s3(target_label=\"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a23450",
   "metadata": {},
   "source": [
    "# Next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "colmap_dir = r\"C:\\Users\\zzballabe1\\Documents\\COLMAP\"\n",
    "print(\"Files in COLMAP directory:\", os.listdir(colmap_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05b03fe",
   "metadata": {},
   "source": [
    "def run_colmap_pipeline():\n",
    "    \"\"\"Run the complete COLMAP pipeline, skipping steps that are already completed\"\"\"\n",
    "    colmap_dir = os.path.join(base_dir, \"colmap\")\n",
    "    images_dir = os.path.join(base_dir, \"images\")\n",
    "    sparse_dir = os.path.join(colmap_dir, \"sparse\")\n",
    "    dense_dir = os.path.join(colmap_dir, \"dense\")\n",
    "    results_dir = os.path.join(base_dir, \"results\")\n",
    "    os.makedirs(colmap_dir, exist_ok=True)\n",
    "    os.makedirs(sparse_dir, exist_ok=True)\n",
    "    os.makedirs(dense_dir, exist_ok=True)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Define the full path to COLMAP executable\n",
    "    colmap_exe = r\"C:\\Users\\zzballabe1\\Documents\\COLMAP\\COLMAP.bat\"\n",
    "    \n",
    "    # Check for database file\n",
    "    db_path = os.path.join(colmap_dir, \"database.db\")\n",
    "    if not os.path.exists(db_path):\n",
    "        # 1. Feature extraction\n",
    "        print(\"Step 1: Feature extraction\")\n",
    "        cmd = [\n",
    "            colmap_exe, \"feature_extractor\",\n",
    "            \"--database_path\", db_path,\n",
    "            \"--image_path\", images_dir\n",
    "        ]\n",
    "        subprocess.run(cmd)\n",
    "    else:\n",
    "        print(\"✅ Step 1: Feature extraction already completed\")\n",
    "    \n",
    "    # Check if feature matching is done (harder to detect, check database size)\n",
    "    if os.path.exists(db_path) and os.path.getsize(db_path) < 10000000:  # Arbitrary threshold\n",
    "        # 2. Feature matching\n",
    "        print(\"Step 2: Feature matching\")\n",
    "        cmd = [\n",
    "            colmap_exe, \"exhaustive_matcher\",\n",
    "            \"--database_path\", db_path\n",
    "        ]\n",
    "        subprocess.run(cmd)\n",
    "    else:\n",
    "        print(\"✅ Step 2: Feature matching already completed\")\n",
    "    \n",
    "    # Check for sparse reconstruction\n",
    "    sparse_0_dir = os.path.join(sparse_dir, \"0\")\n",
    "    if not os.path.exists(sparse_0_dir) or len(os.listdir(sparse_0_dir)) < 4:\n",
    "        # 3. Sparse reconstruction\n",
    "        print(\"Step 3: Sparse reconstruction\")\n",
    "        cmd = [\n",
    "            colmap_exe, \"mapper\",\n",
    "            \"--database_path\", db_path,\n",
    "            \"--image_path\", images_dir,\n",
    "            \"--output_path\", sparse_dir\n",
    "        ]\n",
    "        subprocess.run(cmd)\n",
    "    else:\n",
    "        print(\"✅ Step 3: Sparse reconstruction already completed\")\n",
    "    \n",
    "    # Check for image undistortion\n",
    "    dense_images_dir = os.path.join(dense_dir, \"images\")\n",
    "    if not os.path.exists(dense_images_dir) or len(os.listdir(dense_images_dir)) < 10:\n",
    "        # 4. Image undistortion\n",
    "        print(\"Step 4: Image undistortion\")\n",
    "        cmd = [\n",
    "            colmap_exe, \"image_undistorter\",\n",
    "            \"--image_path\", images_dir,\n",
    "            \"--input_path\", os.path.join(sparse_dir, \"0\"),\n",
    "            \"--output_path\", dense_dir,\n",
    "            \"--output_type\", \"COLMAP\"\n",
    "        ]\n",
    "        subprocess.run(cmd)\n",
    "    else:\n",
    "        print(\"✅ Step 4: Image undistortion already completed\")\n",
    "    \n",
    "    # Check for patch match stereo completion\n",
    "    stereo_dir = os.path.join(dense_dir, \"stereo\")\n",
    "    depth_maps_dir = os.path.join(stereo_dir, \"depth_maps\") if os.path.exists(stereo_dir) else None\n",
    "    \n",
    "    # Count number of images to process\n",
    "    if os.path.exists(dense_images_dir):\n",
    "        image_files = [f for f in os.listdir(dense_images_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "        total_images = len(image_files)\n",
    "    else:\n",
    "        total_images = 0\n",
    "    \n",
    "    # Check if all depth maps are created\n",
    "    if not depth_maps_dir or not os.path.exists(depth_maps_dir) or len(os.listdir(depth_maps_dir)) < total_images:\n",
    "        # 5. Patch match stereo\n",
    "        print(\"Step 5: Patch match stereo\")\n",
    "        cmd = [\n",
    "            colmap_exe, \"patch_match_stereo\",\n",
    "            \"--workspace_path\", dense_dir\n",
    "        ]\n",
    "        subprocess.run(cmd)\n",
    "    else:\n",
    "        print(\"✅ Step 5: Patch match stereo already completed\")\n",
    "    \n",
    "    # Check for final point cloud\n",
    "    fused_ply = os.path.join(results_dir, \"fused.ply\")\n",
    "    if not os.path.exists(fused_ply):\n",
    "        # 6. Stereo fusion\n",
    "        print(\"Step 6: Stereo fusion\")\n",
    "        cmd = [\n",
    "            colmap_exe, \"stereo_fusion\",\n",
    "            \"--workspace_path\", dense_dir,\n",
    "            \"--output_path\", fused_ply\n",
    "        ]\n",
    "        subprocess.run(cmd)\n",
    "    else:\n",
    "        print(\"✅ Step 6: Stereo fusion already completed\")\n",
    "    \n",
    "    # Check for model TXT export\n",
    "    model_txt_dir = os.path.join(colmap_dir, \"model_txt\", \"0\")\n",
    "    if not os.path.exists(model_txt_dir) or len(os.listdir(model_txt_dir)) < 3:\n",
    "        # Export model to TXT format for later use\n",
    "        os.makedirs(os.path.dirname(model_txt_dir), exist_ok=True)\n",
    "        print(\"Step 7: Exporting model to TXT format\")\n",
    "        cmd = [\n",
    "            colmap_exe, \"model_converter\",\n",
    "            \"--input_path\", os.path.join(sparse_dir, \"0\"),\n",
    "            \"--output_path\", model_txt_dir,\n",
    "            \"--output_type\", \"TXT\"\n",
    "        ]\n",
    "        subprocess.run(cmd)\n",
    "    else:\n",
    "        print(\"✅ Step 7: Model export to TXT already completed\")\n",
    "    \n",
    "    # Final check\n",
    "    if os.path.exists(fused_ply) and os.path.exists(model_txt_dir):\n",
    "        print(\"✅ COLMAP pipeline completed successfully\")\n",
    "        print(f\"✅ Dense point cloud saved to: {fused_ply}\")\n",
    "        print(f\"✅ Model exported to TXT format: {model_txt_dir}\")\n",
    "    else:\n",
    "        print(\"⚠️ COLMAP pipeline not fully completed\")\n",
    "        if not os.path.exists(fused_ply):\n",
    "            print(\"  Missing final point cloud\")\n",
    "        if not os.path.exists(model_txt_dir):\n",
    "            print(\"  Missing TXT model export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323398d7",
   "metadata": {},
   "source": [
    "# Visual Digital Twin Workflow Documentation\n",
    "\n",
    "## Overview\n",
    "\n",
    "This workflow transforms a video of a space into a 3D digital twin with object detection capabilities. It combines computer vision, photogrammetry, and 3D visualization to create an accurate spatial representation with identified objects.\n",
    "\n",
    "## Software Requirements\n",
    "\n",
    "1. **Python Libraries**:\n",
    "   - `numpy`: For numerical operations\n",
    "   - `open3d`: For 3D point cloud and mesh processing\n",
    "   - `ultralytics`: For YOLOv8 object detection\n",
    "   - `opencv-python`: For image processing\n",
    "\n",
    "2. **External Software**:\n",
    "   - `COLMAP`: Structure-from-Motion and Multi-View Stereo software\n",
    "   - `FFmpeg`: For video frame extraction\n",
    "\n",
    "## Workflow Phases\n",
    "\n",
    "### Cell 1: Setup and Imports\n",
    "Imports necessary libraries and sets up the base directory structure. This cell handles basic configuration and suppresses SSL warnings that might occur in secure environments.\n",
    "\n",
    "### Cell 2: Directory Structure Creation\n",
    "Creates the folder structure needed for the workflow:\n",
    "- `video`: Stores input video files\n",
    "- `images`: Contains extracted video frames\n",
    "- `images_down`: Optional folder for downsampled images\n",
    "- `colmap`: Stores COLMAP reconstruction outputs\n",
    "- `detections`: Contains object detection results\n",
    "- `results`: Stores final outputs (point clouds, 3D detections)\n",
    "- `scripts`: Helper scripts\n",
    "\n",
    "### Cell 3: Frame Extraction Functions\n",
    "Defines functions to extract frames from video at a specified frame rate using FFmpeg. The extracted frames are then copied to the images directory for further processing.\n",
    "\n",
    "**What it does**: Converts video into a sequence of still images that can be used for 3D reconstruction.\n",
    "\n",
    "### Cell 4: COLMAP Reconstruction Pipeline\n",
    "Implements the complete COLMAP photogrammetry pipeline:\n",
    "1. Feature extraction: Detects distinctive points in each image\n",
    "2. Feature matching: Finds correspondences between images\n",
    "3. Sparse reconstruction: Calculates camera positions and a sparse point cloud\n",
    "4. Dense reconstruction: Creates a detailed 3D point cloud\n",
    "\n",
    "**What it does**: Transforms 2D images into a 3D representation of the environment.\n",
    "\n",
    "### Cell 5: YOLO Object Detection\n",
    "Runs YOLOv8 object detection on the extracted frames to identify objects of interest. Results are saved as annotated images and a structured JSON file containing bounding box coordinates and object labels.\n",
    "\n",
    "**What it does**: Identifies objects in the 2D images with their precise locations.\n",
    "\n",
    "### Cell 6: 2D to 3D Projection Helper Functions\n",
    "Defines utility functions for loading COLMAP's output files and processing the 3D data:\n",
    "- Loading 3D points from COLMAP's text format\n",
    "- Loading image data with 2D-to-3D point correspondences\n",
    "- Filtering points within bounding boxes\n",
    "- Computing robust center points\n",
    "\n",
    "**What it does**: Provides tools to bridge between 2D detections and 3D space.\n",
    "\n",
    "### Cell 7: 2D to 3D Projection Main Function\n",
    "Projects 2D object detections into 3D space by:\n",
    "1. Finding 3D points that project into the object's bounding box\n",
    "2. Computing the median position of these points as the object's 3D location\n",
    "3. Saving the 3D positions as colored markers and a structured JSON file\n",
    "\n",
    "**What it does**: Places detected objects in their correct 3D positions within the reconstructed space.\n",
    "\n",
    "### Cell 8: Detection Sphere Creation\n",
    "Creates a sphere that encompasses all instances of a detected object:\n",
    "1. Clusters nearby detections of the same object\n",
    "2. Computes the center and radius to enclose all instances\n",
    "3. Generates a 3D sphere mesh and visualizes it within the point cloud\n",
    "\n",
    "**What it does**: Creates a visual representation of the object's location and approximate size in 3D space.\n",
    "\n",
    "### Cell 9: Complete Workflow Execution\n",
    "Provides a function to run the entire pipeline from start to finish:\n",
    "1. Frame extraction from video\n",
    "2. COLMAP 3D reconstruction\n",
    "3. YOLO object detection\n",
    "4. 2D to 3D projection\n",
    "5. Detection sphere creation\n",
    "\n",
    "**What it does**: Orchestrates the entire process from video input to 3D visualization with detected objects.\n",
    "\n",
    "## Practical Applications\n",
    "\n",
    "This workflow enables:\n",
    "- Creating accurate 3D models of physical spaces\n",
    "- Identifying and localizing objects within those spaces\n",
    "- Visualizing object positions in 3D\n",
    "- Measuring spatial relationships between objects\n",
    "- Supporting augmented reality and digital twin applications\n",
    "\n",
    "The resulting 3D model with object detections can be used for space planning, asset tracking, virtual tours, and integration with CAD systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec41542f",
   "metadata": {},
   "source": [
    "# Visual Digital Twin Workflow: Inputs and Outputs\n",
    "\n",
    "## Cell 1: Setup and Imports\n",
    "**Inputs:** None  \n",
    "**Outputs:** Configured environment with base directory\n",
    "\n",
    "## Cell 2: Directory Structure Creation\n",
    "**Inputs:** Base directory path  \n",
    "**Outputs:** Created directories:\n",
    "- `video/`: For input video files\n",
    "- `images/`: For extracted frames\n",
    "- `images_down/`: For downsampled images (optional)\n",
    "- `colmap/`: For COLMAP reconstruction outputs\n",
    "- `detections/`: For object detection results\n",
    "- `results/`: For final outputs\n",
    "- `scripts/`: For helper scripts\n",
    "\n",
    "## Cell 3: Frame Extraction Functions\n",
    "**Inputs:** Video file (e.g., `room.MP4`)  \n",
    "**Outputs:** \n",
    "- Extracted frames in `frames/` directory\n",
    "- Copied frames in `images/` directory\n",
    "\n",
    "## Cell 4: COLMAP Reconstruction Pipeline\n",
    "**Inputs:** Images in `images/` directory  \n",
    "**Outputs:**\n",
    "- COLMAP database: `colmap/database.db`\n",
    "- Sparse reconstruction: `colmap/sparse/`\n",
    "- Dense reconstruction: `colmap/dense/`\n",
    "- Text model: `colmap/model_txt/0/`\n",
    "- Point cloud: `results/fused.ply`\n",
    "\n",
    "## Cell 5: YOLO Object Detection\n",
    "**Inputs:**\n",
    "- Images in `images/` directory\n",
    "- YOLOv8 model (downloaded automatically)  \n",
    "\n",
    "**Outputs:**\n",
    "- Annotated images: `detections/yolo_out/`\n",
    "- Detection JSON: `detections/detections.json`\n",
    "\n",
    "## Cell 6: 2D to 3D Projection Helper Functions\n",
    "**Inputs:** None (defines functions only)  \n",
    "**Outputs:** Helper functions for 2D-to-3D projection\n",
    "\n",
    "## Cell 7: 2D to 3D Projection Main Function\n",
    "**Inputs:**\n",
    "- COLMAP text model: `colmap/model_txt/0/`\n",
    "- Detection JSON: `detections/detections.json`\n",
    "- Point cloud: `results/fused.ply` (for visualization)  \n",
    "\n",
    "**Outputs:**\n",
    "- 3D markers: `results/<target_label>_markers.ply`\n",
    "- 3D detections JSON: `results/<target_label>_detections_3d.json`\n",
    "- 3D visualization (interactive)\n",
    "\n",
    "## Cell 8: Detection Sphere Creation\n",
    "**Inputs:**\n",
    "- 3D detections JSON: `results/<target_label>_detections_3d.json`\n",
    "- Point cloud: `results/fused.ply` (for visualization)  \n",
    "\n",
    "**Outputs:**\n",
    "- 3D sphere mesh: `results/<target_label>_sphere_single.ply`\n",
    "- 3D visualization (interactive)\n",
    "\n",
    "## Cell 9: Complete Workflow Execution\n",
    "**Inputs:**\n",
    "- Video file\n",
    "- Target object label (e.g., 'dog')  \n",
    "\n",
    "**Outputs:** All outputs from cells 1-8\n",
    "\n",
    "## File Format Details\n",
    "- **PLY**: Polygon File Format for 3D data\n",
    "- **JSON**: JavaScript Object Notation for structured data\n",
    "- **DB**: SQLite database used by COLMAP\n",
    "- **TXT**: Text files containing camera parameters and 3D points"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
